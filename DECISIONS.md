# Architecture Decision Records

This document captures key architectural decisions for `cuttledoc`.

---

## ADR-001: Multi-Backend Architecture

**Status:** Accepted
**Date:** 2024-12-16

### Context

Local speech-to-text has multiple viable approaches, each with trade-offs:

| Approach | Pros | Cons |
|----------|------|------|
| Apple Speech | Native, fast, no download | macOS only |
| Whisper (OpenAI) | High quality, 99 languages | Large models, slower |
| Parakeet (NVIDIA) | Fastest for EU languages | 25 languages only |
| Cloud APIs | Best quality | Requires internet, costs money |

### Decision

Implement a **unified API with pluggable backends**:

```typescript
const result = await transcribe("audio.wav", {
  language: "de",
  backend: "auto" // or "apple", "sherpa"
});
```

Backend selection:
1. **Auto mode**: Select best available backend for platform/language
2. **Explicit mode**: User specifies preferred backend

### Consequences

- âœ… Users get optimal performance without configuration
- âœ… Cross-platform support with single API
- âš ï¸ More complex codebase with multiple backends
- âš ï¸ Testing matrix grows with each backend

---

## ADR-002: sherpa-onnx over Raw ONNX Runtime

**Status:** Accepted
**Date:** 2024-12-16

### Context

For cross-platform speech recognition, we evaluated:

| Option | Runtime Size | Node.js Bindings | Models Supported |
|--------|--------------|------------------|------------------|
| `onnxruntime-node` | ~100MB | âœ… Official | Any ONNX |
| `sherpa-onnx` | ~40MB | âœ… Official | Speech-optimized |
| `whisper.cpp` | ~2MB | ğŸ”¨ Build yourself | Whisper only |
| MLX (Apple) | ~50MB | âŒ Python only | Apple Silicon only |

### Decision

Use **sherpa-onnx** as the primary cross-platform backend.

Reasons:
1. **Official Node.js bindings** - `npm install sherpa-onnx`
2. **Smaller runtime** - ~40MB vs ~100MB for full ONNX Runtime
3. **Multi-model support** - Whisper, Parakeet v3, Paraformer in one runtime
4. **Speech-optimized** - Built by k2-fsa team (Kaldi successor)
5. **Streaming support** - Real-time transcription possible
6. **Active development** - Regular updates, good community

### Consequences

- âœ… One backend covers Whisper + Parakeet + more
- âœ… Smaller dependency footprint than raw ONNX Runtime
- âœ… Streaming transcription possible in future
- âš ï¸ Dependent on k2-fsa team's maintenance
- âš ï¸ Not as widely known as whisper.cpp

---

## ADR-003: Parakeet v3 INT8 as Default for EU Languages

**Status:** Accepted
**Date:** 2024-12-16

### Context

For European languages (de, en, fr, es, it, etc.), multiple models are viable:

| Model | Size | Speed | Quality | Languages |
|-------|------|-------|---------|-----------|
| Whisper large-v3 | 3GB | Slow | Best | 99 |
| Whisper small | 466MB | Medium | Good | 99 |
| Parakeet v3 FP32 | 600MB | Fast | Excellent | 25 EU |
| Parakeet v3 INT8 | ~150MB | Fastest | Excellent | 25 EU |

### Decision

Use **Parakeet v3 INT8** as default for EU languages:

```typescript
// Auto-selection logic
if (isEuropeanLanguage(lang) && !userPreferredModel) {
  return "parakeet-tdt-0.6b-v3-int8";
}
return "whisper-small"; // fallback
```

### Consequences

- âœ… Best speed/quality ratio for EU languages
- âœ… Smaller download than Whisper large
- âš ï¸ ~1.2GB RAM usage at runtime
- âš ï¸ Non-EU languages fall back to Whisper

---

## ADR-004: Native Addon for Apple Speech

**Status:** Accepted
**Date:** 2024-12-16

### Context

Apple Speech Framework requires native macOS code. Options:

| Approach | Complexity | Performance | Maintenance |
|----------|------------|-------------|-------------|
| N-API + Objective-C++ | High | Best | Medium |
| Swift executable + IPC | Medium | Good | Low |
| AppleScript/osascript | Low | Poor | Low |

### Decision

Use **N-API with Objective-C++** for direct integration:

```cpp
// speech.mm
[recognizer recognitionTaskWithRequest:request
    resultHandler:^(SFSpeechRecognitionResult* result, NSError* error) {
        // Direct callback to Node.js
    }];
```

Reasons:
1. No subprocess overhead
2. Direct memory sharing
3. Proper async handling with N-API AsyncWorker
4. Type-safe interface via TypeScript

### Consequences

- âœ… Best performance, no IPC overhead
- âœ… Proper error propagation
- âš ï¸ Requires Xcode Command Line Tools to build
- âš ï¸ More complex build setup (binding.gyp)

---

## ADR-005: ESM-Only Package

**Status:** Accepted
**Date:** 2024-12-16

### Context

Node.js supports both CommonJS and ESM. Modern packages trend toward ESM-only.

### Decision

Ship as **ESM-only** (`"type": "module"`):

```json
{
  "type": "module",
  "exports": {
    ".": {
      "import": "./dist/index.js",
      "types": "./dist/index.d.ts"
    }
  }
}
```

Reasons:
1. Node.js 24+ has mature ESM support
2. Better tree-shaking
3. Simpler build (no dual CJS/ESM)
4. Top-level await support

### Consequences

- âœ… Cleaner codebase
- âœ… Better bundler compatibility
- âš ï¸ CJS users must use dynamic import
- âš ï¸ Requires Node.js 18+ (we target 24+)

---

## ADR-006: Lazy Backend Loading

**Status:** Accepted
**Date:** 2024-12-16

### Context

Loading all backends at startup wastes resources if user only needs one.

### Decision

**Lazy-load backends** on first use:

```typescript
export async function transcribe(audioPath: string, options: TranscribeOptions) {
  const backend = options.backend ?? selectBestBackend();

  switch (backend) {
    case "apple": {
      // Only import when needed
      const { AppleBackend } = await import("./backends/apple/index.js");
      return new AppleBackend().transcribe(audioPath, options);
    }
    case "sherpa": {
      const { SherpaBackend } = await import("./backends/sherpa/index.js");
      // ...
    }
  }
}
```

### Consequences

- âœ… Faster startup time
- âœ… Smaller memory footprint when using single backend
- âš ï¸ First transcription has import overhead
- âš ï¸ Slightly more complex code

---

## ADR-007: Native FFmpeg Bindings for Audio Preprocessing

**Status:** Accepted
**Date:** 2024-12-16

### Context

Speech recognition models typically require 16kHz mono WAV input. Users have audio in various formats (mp3, m4a, flac, etc.).

| Option | Approach | Streaming | Binary Size |
|--------|----------|-----------|-------------|
| `ffmpeg` CLI | Subprocess | No (wait for file) | External dep |
| `fluent-ffmpeg` | Subprocess wrapper | Partial | External dep |
| `@mmomtchev/ffmpeg` | Native bindings | Yes (streams) | ~50MB bundled |
| `@ffprobe-installer` | Download binary | No | ~30MB download |

### Decision

Use **@mmomtchev/ffmpeg** native bindings:

```typescript
import { Demuxer, AudioDecoder, AudioTransform } from "@mmomtchev/ffmpeg/stream";

async function* streamAudioSamples(path: string) {
  const demuxer = new Demuxer({ inputFile: path });
  const decoder = new AudioDecoder({ stream: demuxer.audio[0] });
  const resampler = new AudioTransform({
    input: decoder.definition(),
    output: { sampleRate: 16000, channels: 1, format: "flt" }
  });

  decoder.pipe(resampler);

  for await (const frame of resampler) {
    yield frame.data as Float32Array;
  }
}
```

Reasons:
1. **True streaming** - Transcription can start before file is fully decoded
2. **No external dependency** - FFmpeg bundled as native addon
3. **Async, multi-threaded** - Leverages Node.js worker pool
4. **Format coverage** - All FFmpeg codecs (mp3, aac, flac, opus, etc.)

### Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Input: podcast.mp3                                      â”‚
â”‚           â”‚                                              â”‚
â”‚           â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚ Demuxer         â”‚  â† Native ffmpeg, async            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚           â”‚ Readable stream                              â”‚
â”‚           â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚ AudioDecoder    â”‚  â† Compressed â†’ Raw samples        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚           â”‚                                              â”‚
â”‚           â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚ AudioTransform  â”‚  â† Resample to 16kHz mono float32  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚           â”‚ AsyncGenerator<Float32Array>                 â”‚
â”‚           â–¼                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚  â”‚ sherpa-onnx     â”‚  â† acceptWaveform() with chunks    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Consequences

- âœ… Streaming pipeline - no waiting for full decode
- âœ… Self-contained - no ffmpeg install required
- âœ… Consistent behavior across platforms
- âš ï¸ ~50MB added to package size
- âš ï¸ ESLint strict rules require some `any` type annotations

---

## Future Considerations

### Potential ADRs

- **ADR-008**: Model caching and download strategy
- **ADR-009**: Worker thread isolation for heavy processing
- **ADR-010**: Browser/WebAssembly support
- **ADR-011**: Streaming transcription API design

---

*Last updated: 2024-12-16*

