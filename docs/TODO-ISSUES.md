# Known Issues & Future Improvements

Diese Liste dokumentiert erkannte Probleme und m√∂gliche Verbesserungen f√ºr zuk√ºnftige Arbeit.

---

## üî¥ Kritische Issues

### 1. Parakeet v3 int8 erkennt Franz√∂sisch nicht korrekt

**Status:** Offen  
**Priorit√§t:** Hoch  
**Entdeckt:** 2025-01-02

**Problem:**

- Das Parakeet-TDT-0.6b-v3 Modell in der int8-quantisierten Version erkennt Franz√∂sisch nicht korrekt
- Statt franz√∂sischer Transkription wird ein Englisch-Franz√∂sisch-Mischmasch ausgegeben
- WER f√ºr FR: 86-97% (unbrauchbar)
- Andere Sprachen (DE, ES, PT) funktionieren mit ~3-8% WER

**Ursache (vermutet):**

- Die int8-Quantisierung hat m√∂glicherweise die franz√∂sische Spracherkennung besch√§digt
- v3 gibt es nur als int8, keine fp16/fp32 Version verf√ºgbar
- MacWhisper mit "Parakeet v3" funktioniert - verwendet m√∂glicherweise andere Modellquelle

**Workaround:**

- Whisper-large-v3 f√ºr franz√∂sische Inhalte verwenden

**M√∂gliche L√∂sungen:**

- [ ] Issue bei Sherpa-ONNX √∂ffnen: https://github.com/k2-fsa/sherpa-onnx/issues
- [ ] fp16-Version von v3 selbst aus NeMo-Modell konvertieren
- [ ] Pr√ºfen ob NVIDIA eine ONNX-Version bereitstellt

**Referenzen:**

- Sherpa-ONNX Releases: https://github.com/k2-fsa/sherpa-onnx/releases/tag/asr-models
- NeMo Parakeet v3: https://huggingface.co/nvidia/parakeet-tdt-0.6b-v3

---

## üü° Verbesserungen

### 2. LLM-Benchmark mit l√§ngeren Samples

**Status:** Erledigt ‚úÖ  
**Priorit√§t:** Mittel

**Problem:**

- FLEURS-Samples sind zu kurz (~10-15 Sek) f√ºr aussagekr√§ftige LLM-Korrektur-Benchmarks
- Einzelne S√§tze bieten wenig Kontext f√ºr sinnvolle Korrekturen

**L√∂sung:**

- ‚úÖ L√§ngere TTS-generierte Texte (~5-7 Minuten pro Sprache)
- ‚úÖ Wikipedia-artige Texte mit ElevenLabs TTS erstellt
- ‚úÖ Benchmark mit allen 5 Sprachen abgeschlossen (2025-01-02)

**Ergebnisse (Whisper STT ‚Üí LLM-Korrektur):**

| Modell   | √ò WER vorher | √ò WER nachher | Verbesserung | Speed  |
| -------- | ------------ | ------------- | ------------ | ------ |
| gemma3n  | 9.2%         | 3.8%          | +59%         | 37 t/s |
| phi4:14b | 9.2%         | 4.2%          | +54%         | 36 t/s |

**Erkenntnisse:**

- LLM-Korrektur verbessert in 9/10 F√§llen die Ergebnisse
- Besonders effektiv bei hohem WER (>10%): Verbesserungen bis zu 78%
- Minimale Verschlechterung in Einzelf√§llen (~0.7 Prozentpunkte)
- **Empfehlung:** LLM standardm√§√üig aktivieren

---

### 3. Parakeet Sprach-Parameter wird ignoriert

**Status:** Offen  
**Priorit√§t:** Mittel

**Problem:**

- Der `--language` Parameter bei Parakeet scheint ignoriert zu werden
- Transducer-Modelle in Sherpa-ONNX haben keine explizite Spracheinstellung
- Nur Whisper-Modelle unterst√ºtzen `language` Parameter in der Config

**Zu kl√§ren:**

- [ ] Wie funktioniert Spracherkennung bei Parakeet/Transducer-Modellen?
- [ ] Ist automatische Spracherkennung implementiert?
- [ ] Sherpa-ONNX Dokumentation pr√ºfen

---

### 4. OGG/Opus Dateien im Benchmark-Verzeichnis

**Status:** Erledigt ‚úÖ  
**Priorit√§t:** Niedrig

**Problem:**

- MP3-Dateien waren zu gro√ü f√ºr Repository

**L√∂sung:**

- ‚úÖ Konvertierung zu OGG/Opus (48kbps) - ~3x kleiner
- ‚úÖ .gitignore angepasst

---

## üü¢ Abgeschlossene Issues

### 5. ElevenLabs 5000-Zeichen-Limit

**Status:** Erledigt ‚úÖ

**Problem:**

- Referenztexte waren l√§nger als das ElevenLabs-Limit
- WER-Berechnung war dadurch verf√§lscht

**L√∂sung:**

- ‚úÖ Texte manuell auf passende L√§nge gek√ºrzt

---

### 6. LLM-Korrektur-Prompt verbessert

**Status:** Erledigt ‚úÖ

**Problem:**

- Alter Prompt war zu kurz, Modelle (Mistral, Qwen) √ºbersetzten statt zu korrigieren

**L√∂sung:**

- ‚úÖ Ausf√ºhrlicher Prompt mit expliziten Verboten (DO NOT translate, summarize, rephrase)
- ‚úÖ In `packages/llm/src/types.ts` als `TRANSCRIPT_CORRECTION_PROMPT`

---

## üìù N√§chste Schritte

1. [x] ~~LLM-Benchmark mit Whisper f√ºr alle 5 Sprachen abschlie√üen~~ ‚úÖ
2. [ ] Issue bei Sherpa-ONNX f√ºr Parakeet v3 fp16 √∂ffnen
3. [ ] Ergebnisse in README/Docs √ºbernehmen
4. [x] ~~Entscheiden welches LLM-Modell als Default~~ ‚Üí **gemma3n** (schneller, leicht besser)
5. [ ] LLM standardm√§√üig aktivieren im CLI
