---
title: Getting Started
description: Fast speech-to-text transcription library for Node.js with local and cloud backends
---

cuttledoc is a fast speech-to-text transcription library for Node.js.
It supports multiple backends (local and cloud) and optional LLM enhancement for formatting transcripts.

## Installation

```bash
pnpm add cuttledoc
```

### Requirements

- Node.js 24+
- ~2GB disk space for models

## CLI Usage

```bash
# Basic transcription (uses local Parakeet)
npx cuttledoc video.mp4

# With LLM enhancement (adds formatting, TLDR, corrections)
npx cuttledoc podcast.mp3 --enhance -o transcript.md

# Use specific backend and language
npx cuttledoc meeting.m4a -b parakeet -l de

# Use OpenAI cloud API (best quality)
export OPENAI_API_KEY=sk-...
npx cuttledoc meeting.m4a -b openai

# Show processing statistics
npx cuttledoc audio.wav --stats
```

## API Usage

```typescript
import { transcribe } from 'cuttledoc'

// Local transcription (offline)
const result = await transcribe('audio.mp3', {
  language: 'en',
  backend: 'auto' // auto, whisper, parakeet, phi4
})

console.log(result.text)
console.log(`Duration: ${result.durationSeconds}s`)

// Cloud transcription (OpenAI)
const cloudResult = await transcribe('audio.mp3', {
  backend: 'openai',
  apiKey: process.env.OPENAI_API_KEY
})
```

## With LLM Enhancement

```typescript
import { transcribe } from 'cuttledoc'
import { enhanceTranscript } from 'cuttledoc/llm'

const result = await transcribe('podcast.mp3')

const enhanced = await enhanceTranscript(result.text, {
  model: 'gemma3n:e4b',
  mode: 'enhance' // or 'correct' for minimal changes
})

console.log(enhanced.markdown)
```

## Quality Benchmark

Word Error Rate (WER) on [FLEURS](https://huggingface.co/datasets/google/fleurs) native speaker recordings:

| Backend               | üá¨üáß EN | üá™üá∏ ES | üá©üá™ DE | üá´üá∑ FR | üáßüá∑ PT | Avg WER | RTF  |
| --------------------- | ----- | ----- | ----- | ----- | ----- | ------- | ---- |
| **gpt-4o-transcribe** | 9.9%  | 2.1%  | 2.8%  | 6.3%  | 4.6%  | 5.1%    | 0.16 |
| **Whisper large-v3**  | 4.9%  | 2.1%  | 2.8%  | 10.6% | 5.2%  | 5.1%    | 2.2  |
| **Canary-1B-v2**      | 8.2%  | 3.2%  | 2.8%  | 7.9%  | 5.7%  | 5.6%    | 0.57 |
| **Phi-4-multimodal**  | 3.3%  | 2.5%  | 3.7%  | 10.2% | 10.7% | 6.1%    | 0.56 |
| **Parakeet v3**       | 4.6%  | 3.6%  | 4.5%  | 10.1% | 9.0%  | 6.4%    | 0.24 |

_RTF = Real-Time Factor (lower = faster). All values measured on Apple M1 Pro._

### üèÜ Ranking by Accuracy

| Rank | Backend               | Avg WER | Best for                           |
| ---- | --------------------- | ------- | ---------------------------------- |
| ü•á   | **gpt-4o-transcribe** | 5.1%    | Cloud, best for FR/PT              |
| ü•á   | **Whisper large-v3**  | 5.1%    | Offline, broadest language support |
| ü•â   | **Canary-1B-v2**      | 5.6%    | Best DE accuracy, 26 EU languages  |
| 4    | **Phi-4-multimodal**  | 6.1%    | Best EN/ES accuracy, local GPU     |
| 5    | **Parakeet v3**       | 6.4%    | Fast + accurate, 25 European langs |

### ‚ö° Ranking by Speed

| Rank | Backend               | RTF  | Best for                        |
| ---- | --------------------- | ---- | ------------------------------- |
| ü•á   | **gpt-4o-transcribe** | 0.16 | Cloud, fastest overall          |
| ü•à   | **Parakeet v3**       | 0.24 | Real-time, batch processing     |
| ü•â   | **Phi-4-multimodal**  | 0.56 | Near real-time on MPS/CUDA      |
| 4    | **Canary-1B-v2**      | 0.57 | Near real-time, 26 EU languages |
| 5    | **Whisper large-v3**  | 2.2  | Quality-focused, offline on CPU |

_RTF = Real-Time Factor. 0.16 means 10s audio transcribed in 1.6s._

## Available Backends

### Local Backends (Offline, No API Key)

| Backend                   | RTF  | Avg WER | Languages | Size   | Requires    |
| ------------------------- | ---- | ------- | --------- | ------ | ----------- |
| **Parakeet v3** (default) | 0.24 | 6.4%    | 25        | 160 MB | Node.js     |
| **Whisper large-v3**      | 2.2  | 5.1%    | 99        | 1.6 GB | Node.js     |
| **Phi-4-multimodal**      | 0.56 | 6.1%    | 8         | 12 GB  | Python, GPU |
| **Canary-1B-v2**          | 0.57 | 5.6%    | 26        | 1 GB   | Python, GPU |

### Cloud Backends (Requires API Key)

| Backend                    | RTF  | Avg WER | Languages | Cost        |
| -------------------------- | ---- | ------- | --------- | ----------- |
| **gpt-4o-transcribe**      | 0.16 | 5.1%    | 50+       | ~$0.006/min |
| **gpt-4o-mini-transcribe** | 0.12 | ~6%     | 50+       | ~$0.003/min |

## Model Management

```bash
# List available models
cuttledoc models list

# Download speech models
cuttledoc models download parakeet-tdt-0.6b-v3   # 160 MB, 25 languages
cuttledoc models download whisper-large-v3       # 1.6 GB, 99 languages

# Download LLM model (for --enhance)
cuttledoc models download gemma3n:e4b
```

## Next Steps

<Cards>
  <Card title="API Reference" href="/docs/api" />
  <Card title="GitHub" href="https://github.com/sebastian-software/cuttledoc" />
</Cards>
