---
title: Getting Started
description: Fast speech-to-text transcription library for Node.js with local and cloud backends
---

cuttledoc is a fast speech-to-text transcription library for Node.js.
It supports multiple backends (local and cloud) and optional LLM enhancement for formatting transcripts.

## Installation

```bash
pnpm add cuttledoc
```

### Requirements

- Node.js 24+
- ~2GB disk space for models

## CLI Usage

```bash
# Basic transcription (uses local Parakeet)
npx cuttledoc video.mp4

# With LLM enhancement (adds formatting, TLDR, corrections)
npx cuttledoc podcast.mp3 --enhance -o transcript.md

# Use specific backend and language
npx cuttledoc meeting.m4a -b parakeet -l de

# Use OpenAI cloud API (best quality)
export OPENAI_API_KEY=sk-...
npx cuttledoc meeting.m4a -b openai

# Show processing statistics
npx cuttledoc audio.wav --stats
```

## API Usage

```typescript
import { transcribe } from 'cuttledoc'

// Local transcription (offline)
const result = await transcribe('audio.mp3', {
  language: 'en',
  backend: 'auto' // auto, whisper, parakeet, phi4
})

console.log(result.text)
console.log(`Duration: ${result.durationSeconds}s`)

// Cloud transcription (OpenAI)
const cloudResult = await transcribe('audio.mp3', {
  backend: 'openai',
  apiKey: process.env.OPENAI_API_KEY
})
```

## With LLM Enhancement

```typescript
import { transcribe } from 'cuttledoc'
import { enhanceTranscript } from 'cuttledoc/llm'

const result = await transcribe('podcast.mp3')

const enhanced = await enhanceTranscript(result.text, {
  model: 'gemma3n:e4b',
  mode: 'enhance' // or 'correct' for minimal changes
})

console.log(enhanced.markdown)
```

## Quality Benchmark

Word Error Rate (WER) on raw STT output (before LLM enhancement), averaged across 5 languages:

| Backend               | üá¨üáß EN | üá©üá™ DE | üá´üá∑ FR | üá™üá∏ ES | üáßüá∑ PT | Avg WER | Speed |
| --------------------- | ----- | ----- | ----- | ----- | ----- | ------- | ----- |
| **Parakeet v3**       | 5.2%  | 7.8%  | 8.1%  | 6.4%  | 9.2%  | 7.3%    | 6x    |
| **Whisper large-v3**  | 2.9%  | 4.5%  | 4.8%  | 3.9%  | 5.1%  | 4.2%    | 2x    |
| **gpt-4o-transcribe** | 2.1%  | 3.2%  | 3.5%  | 2.8%  | 3.8%  | 3.1%    | cloud |
| **Phi-4-multimodal**  | 3.3%  | 3.7%  | 4.2%  | 3.1%  | 4.5%  | 3.8%    | 1x    |

### üèÜ Ranking by Accuracy

| Rank | Backend               | Avg WER | Best for                         |
| ---- | --------------------- | ------- | -------------------------------- |
| ü•á   | **gpt-4o-transcribe** | 3.1%    | Production, critical transcripts |
| ü•à   | **Phi-4-multimodal**  | 3.8%    | Offline, GPU available           |
| ü•â   | **Whisper large-v3**  | 4.2%    | Offline, broad language support  |
| 4    | **Parakeet v3**       | 7.3%    | Fast drafts, real-time           |

### ‚ö° Ranking by Speed

| Rank | Backend               | Speed | Best for                    |
| ---- | --------------------- | ----- | --------------------------- |
| ü•á   | **Parakeet v3**       | 6x    | Real-time, batch processing |
| ü•à   | **Whisper large-v3**  | 2x    | Balanced speed/quality      |
| ü•â   | **Phi-4-multimodal**  | 1x    | Near real-time on GPU       |
| 4    | **gpt-4o-transcribe** | cloud | Depends on network latency  |

## Available Backends

### Local Backends (Offline, No API Key)

| Backend                   | Speed | Avg WER | Languages | Size   | Requires    |
| ------------------------- | ----- | ------- | --------- | ------ | ----------- |
| **Parakeet v3** (default) | 6x    | 7.3%    | 25        | 160 MB | Node.js     |
| **Whisper large-v3**      | 2x    | 4.2%    | 99        | 1.6 GB | Node.js     |
| **Phi-4-multimodal**      | 1x    | 3.8%    | 8         | 12 GB  | Python, GPU |
| **Canary-1B-v2**          | 2x    | ~4%     | 26        | 1 GB   | Python, GPU |

### Cloud Backends (Requires API Key)

| Backend                    | Speed | Avg WER | Languages | Cost        |
| -------------------------- | ----- | ------- | --------- | ----------- |
| **gpt-4o-transcribe**      | cloud | 3.1%    | 50+       | ~$0.006/min |
| **gpt-4o-mini-transcribe** | cloud | ~4%     | 50+       | ~$0.003/min |

## Model Management

```bash
# List available models
cuttledoc models list

# Download speech models
cuttledoc models download parakeet-tdt-0.6b-v3   # 160 MB, 25 languages
cuttledoc models download whisper-large-v3       # 1.6 GB, 99 languages

# Download LLM model (for --enhance)
cuttledoc models download gemma3n:e4b
```

## Next Steps

<Cards>
  <Card title="API Reference" href="/docs/api" />
  <Card title="GitHub" href="https://github.com/sebastian-software/cuttledoc" />
</Cards>
